{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0cVDm8m0/EvBktR2wSHHQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meghanaaggadi-1/projects/blob/masterr/amazonML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8VXkbUNSq_F",
        "outputId": "4fee4259-5c79-4c75-ea33-896ee219422f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytesseract opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uak72xRSxw6",
        "outputId": "480f2b83-ba7a-4a4b-a411-af6cb711eb80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "def download_image(image_url, save_dir='images'):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    image_name = os.path.join(save_dir, image_url.split('/')[-1])\n",
        "    response = requests.get(image_url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "        img.save(image_name)\n",
        "        return image_name\n",
        "    else:\n",
        "        print(f\"Failed to download image: {image_url}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "ZgUJCvNrS7n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ALLOWED_UNITS = {\n",
        "    'item_weight': ['gram', 'kilogram', 'ounce', 'pound'],\n",
        "    'item_volume': ['litre', 'millilitre'],\n",
        "    'dimensions': ['centimetre', 'metre', 'millimetre', 'inch'],\n",
        "    'power': ['watt', 'kilowatt'],\n",
        "    # Add more entity types and units as needed\n",
        "}\n"
      ],
      "metadata": {
        "id": "ggf9Ac_qS-Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, target_size)\n",
        "    img = img.astype('float32') / 255.0\n",
        "    img = np.expand_dims(img, axis=0)  # Expand dimensions for model input\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "DbHK9InPTAyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "\n",
        "def extract_text_from_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    text = pytesseract.image_to_string(gray)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "Dr7UGJM1TDDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytesseract"
      ],
      "metadata": {
        "id": "FqcNmhDxTGo3",
        "outputId": "4bfc1c40-4918-49a5-a525-a5eaec6abf4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import csv\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Start timing\n",
        "start_time = time.time()\n",
        "\n",
        "# 1. Limit the number of images for fast downloading\n",
        "def download_image(image_url, save_dir):\n",
        "    image_name = os.path.basename(image_url)\n",
        "    image_path = os.path.join(save_dir, image_name)\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        urllib.request.urlretrieve(image_url, image_path)\n",
        "    return image_path\n",
        "\n",
        "def download_images(df, save_dir, limit=50):  # Limit the number of images for fast execution\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        for index, row in df.iterrows():\n",
        "            if index >= limit:  # Only download a limited number of images for testing\n",
        "                break\n",
        "            executor.submit(download_image, row['image_link'], save_dir)\n",
        "\n",
        "# 2. Load Data (limit dataset for speed)\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/dataset/train.csv').head(50)  # Limit to 50 rows for faster processing\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/dataset/test.csv').head(20)\n",
        "\n",
        "# Adjust image paths if necessary\n",
        "train_df['image_link'] = train_df['image_link'].apply(lambda x: os.path.join(image_save_dir, os.path.basename(x)))\n",
        "test_df['image_link'] = test_df['image_link'].apply(lambda x: os.path.join(image_save_dir, os.path.basename(x)))\n",
        "\n",
        "# Create image directory\n",
        "image_save_dir = '/content/images/'\n",
        "os.makedirs(image_save_dir, exist_ok=True)\n",
        "\n",
        "# Download images for train and test data (limited)\n",
        "download_images(train_df, image_save_dir, limit=50)\n",
        "download_images(test_df, image_save_dir, limit=20)\n",
        "\n",
        "# Verify the existence of images\n",
        "print(\"Training Data Sample:\")\n",
        "print(train_df.head())\n",
        "print(\"Test Data Sample:\")\n",
        "print(test_df.head())\n",
        "\n",
        "# 3. Image Data Generator (smaller image size for faster processing)\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    directory=None,  # Local paths are in the image_link column\n",
        "    x_col='image_link',\n",
        "    y_col='entity_value',\n",
        "    target_size=(64, 64),  # Use smaller image size for quicker processing\n",
        "    batch_size=16,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Check the number of classes found\n",
        "print(\"Classes found:\", train_generator.class_indices)\n",
        "print(\"Number of classes:\", len(train_generator.class_indices))\n",
        "\n",
        "# 4. Build a simpler model with ResNet50 (or use MobileNet for even faster results)\n",
        "def build_model(num_classes):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))  # Smaller input size\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(1024, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 5. Train the Model (reduce epochs for fast execution)\n",
        "num_classes = len(train_generator.class_indices)\n",
        "model = build_model(num_classes)\n",
        "\n",
        "# Check if there are any batches available for training\n",
        "if train_generator.samples > 0:\n",
        "    model.fit(train_generator, epochs=1)  # Only 1 epoch for quicker training\n",
        "else:\n",
        "    print(\"No images found for training.\")\n",
        "\n",
        "# 6. Prediction on Test Data (limit the number of predictions for testing)\n",
        "def preprocess_image(image_path, target_size):\n",
        "    from tensorflow.keras.preprocessing import image\n",
        "    img = image.load_img(image_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array / 255.0\n",
        "\n",
        "def predict_on_test_data(model, test_df, target_size=(64, 64)):\n",
        "    predictions = []\n",
        "    for index, row in test_df.iterrows():\n",
        "        image_path = row['image_link']\n",
        "        if os.path.exists(image_path):\n",
        "            img = preprocess_image(image_path, target_size)\n",
        "            prediction = model.predict(img)\n",
        "            entity_value = np.argmax(prediction)  # Simple decoding for testing purposes\n",
        "            predictions.append((row['index'], entity_value))\n",
        "        else:\n",
        "            predictions.append((row['index'], \"\"))\n",
        "    return predictions\n",
        "\n",
        "# 7. Save Predictions to CSV\n",
        "def save_predictions_to_csv(predictions, output_file='output.csv'):\n",
        "    with open(output_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"index\", \"prediction\"])\n",
        "        for index, prediction in predictions:\n",
        "            writer.writerow([index, prediction])\n",
        "\n",
        "# Make predictions and save them\n",
        "if train_generator.samples > 0:\n",
        "    predictions = predict_on_test_data(model, test_df)\n",
        "    save_predictions_to_csv(predictions, '/content/output.csv')\n",
        "\n",
        "# 8. Sanity Check\n",
        "def run_sanity_check(output_file):\n",
        "    result = subprocess.run(['python', 'src/sanity.py', output_file], capture_output=True, text=True)\n",
        "    print(result.stdout)\n",
        "\n",
        "if train_generator.samples > 0:\n",
        "    run_sanity_check('/content/output.csv')\n",
        "\n",
        "# End timing\n",
        "print(f\"Time taken: {time.time() - start_time} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obazfbphUnX0",
        "outputId": "15eac98d-84e9-4ba1-9309-f5f6dfff3f41"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Sample:\n",
            "                        image_link  group_id  entity_name    entity_value\n",
            "0  /content/images/61I9XdN6OFL.jpg    748919  item_weight      500.0 gram\n",
            "1  /content/images/71gSRbyXmoL.jpg    916768  item_volume         1.0 cup\n",
            "2  /content/images/61BZ4zrjZXL.jpg    459516  item_weight      0.709 gram\n",
            "3  /content/images/612mrlqiI4L.jpg    459516  item_weight      0.709 gram\n",
            "4  /content/images/617Tl40LOXL.jpg    731432  item_weight  1400 milligram\n",
            "Test Data Sample:\n",
            "   index                       image_link  group_id entity_name\n",
            "0      0  /content/images/110EibNyclL.jpg    156839      height\n",
            "1      1  /content/images/11TU2clswzL.jpg    792578       width\n",
            "2      2  /content/images/11TU2clswzL.jpg    792578      height\n",
            "3      3  /content/images/11TU2clswzL.jpg    792578       depth\n",
            "4      4  /content/images/11gHj8dhhrL.jpg    792578       depth\n",
            "Found 50 validated image filenames belonging to 33 classes.\n",
            "Classes found: {'0.35 ounce': 0, '0.709 gram': 1, '1 kilogram': 2, '1.0 cup': 3, '10 kilogram to 15 kilogram': 4, '10.0 ounce': 5, '100 gram': 6, '112 gram': 7, '1400 milligram': 8, '15.5 gram': 9, '150.0 watt': 10, '158.0 gram': 11, '18.55 gram': 12, '2.7 gram': 13, '200 gram': 14, '200.0 gram': 15, '250.0 watt': 16, '26.0 gram': 17, '3.53 ounce': 18, '30.0 kilogram': 19, '30.0 watt': 20, '31.0 ounce': 21, '330.0 pound': 22, '35.0 gram': 23, '36.0 volt': 24, '4.0 gallon': 25, '4.1 kilogram': 26, '48.0 volt': 27, '50.0 gram': 28, '500.0 gram': 29, '5000 milligram': 30, '53 ounce': 31, '800.0 watt': 32}\n",
            "Number of classes: 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.1352 - loss: 4.2728\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
            "\n",
            "Time taken: 78.26968264579773 seconds\n"
          ]
        }
      ]
    }
  ]
}